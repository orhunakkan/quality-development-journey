import { PlaywrightDocScraper } from './scraper.js';
import * as path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function main() {
    const startUrl = 'https://playwright.dev/docs/intro';
    const outputDir = path.join(__dirname, '..', 'output');
    const scrapedDataPath = path.join(outputDir, 'scraped-data.json');

    console.log('ğŸš€ Scraping Playwright Documentation...\n');

    try {
        const scraper = new PlaywrightDocScraper();
        const pages = await scraper.scrapeAll(startUrl);
        await scraper.saveToFile(scrapedDataPath);

        console.log('\nâœ… Scraping complete!');
        console.log(`ğŸ“ Output: ${scrapedDataPath}`);
        console.log(`ğŸ“„ Total pages: ${pages.length}`);

    } catch (error) {
        console.error('âŒ Error:', error);
        process.exit(1);
    }
}

main();
